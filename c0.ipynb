{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09e1189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.24.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from torchvision) (2.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: segmentation-models-pytorch in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from segmentation-models-pytorch) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /home/codespace/.local/lib/python3.12/site-packages (from segmentation-models-pytorch) (2.3.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.12/site-packages (from segmentation-models-pytorch) (11.3.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from segmentation-models-pytorch) (0.6.2)\n",
      "Requirement already satisfied: timm>=0.9 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from segmentation-models-pytorch) (1.0.21)\n",
      "Requirement already satisfied: torch>=1.8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from segmentation-models-pytorch) (2.9.0)\n",
      "Requirement already satisfied: torchvision>=0.9 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from segmentation-models-pytorch) (0.24.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from segmentation-models-pytorch) (4.67.1)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2024.6.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.2)\n",
      "Requirement already satisfied: shellingham in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.2.0)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24->segmentation-models-pytorch) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24->segmentation-models-pytorch) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24->segmentation-models-pytorch) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.24->segmentation-models-pytorch) (0.16.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.8->segmentation-models-pytorch) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.8->segmentation-models-pytorch) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.24->segmentation-models-pytorch) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from typer-slim->huggingface-hub>=0.24->segmentation-models-pytorch) (8.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /home/codespace/.local/lib/python3.12/site-packages (from albumentations) (2.3.1)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /home/codespace/.local/lib/python3.12/site-packages (from albumentations) (1.16.0)\n",
      "Requirement already satisfied: PyYAML in /home/codespace/.local/lib/python3.12/site-packages (from albumentations) (6.0.2)\n",
      "Collecting pydantic>=2.9.2 (from albumentations)\n",
      "  Downloading pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Collecting albucore==0.0.24 (from albumentations)\n",
      "  Downloading albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.24->albumentations)\n",
      "  Downloading stringzilla-4.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (110 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.24->albumentations)\n",
      "  Downloading simsimd-6.5.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (70 kB)\n",
      "Collecting numpy>=1.24.4 (from albumentations)\n",
      "  Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /home/codespace/.local/lib/python3.12/site-packages (from pydantic>=2.9.2->albumentations) (4.14.1)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading albumentations-2.0.8-py3-none-any.whl (369 kB)\n",
      "Downloading albucore-0.0.24-py3-none-any.whl (15 kB)\n",
      "Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Downloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading simsimd-6.5.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading stringzilla-4.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.1/599.1 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: simsimd, typing-inspection, stringzilla, pydantic-core, numpy, annotated-types, pydantic, opencv-python-headless, albucore, albumentations\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.3.1\n",
      "\u001b[2K    Uninstalling numpy-2.3.1:[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/10\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.1━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/10\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [albumentations]m [albumentations]eadless]\n",
      "\u001b[1A\u001b[2KSuccessfully installed albucore-0.0.24 albumentations-2.0.8 annotated-types-0.7.0 numpy-2.2.6 opencv-python-headless-4.12.0.88 pydantic-2.12.3 pydantic-core-2.41.4 simsimd-6.5.3 stringzilla-4.2.3 typing-inspection-0.4.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /home/codespace/.local/lib/python3.12/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pillow in /home/codespace/.local/lib/python3.12/site-packages (11.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: numpy in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.2.6)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n",
    "!pip install segmentation-models-pytorch\n",
    "!pip install albumentations\n",
    "!pip install matplotlib\n",
    "!pip install pillow\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240f3d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from albumentations import Compose, HorizontalFlip, VerticalFlip, RandomRotate90\n",
    "\n",
    "# Permite cargar imágenes truncadas\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "class UrbanDataset(Dataset):\n",
    "    def __init__(self, img_paths, mask_paths, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(self.img_paths[idx]).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(self.mask_paths[idx]).convert(\"L\"))\n",
    "        mask = mask / 255.0  # Normaliza a 0-1\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image, mask = augmented['image'], augmented['mask']\n",
    "        \n",
    "        # Convertir a tensores\n",
    "        image = torch.tensor(image).permute(2,0,1).float() / 255.0\n",
    "        mask = torch.tensor(mask).unsqueeze(0).float()\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "620c9542",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    HorizontalFlip(),\n",
    "    VerticalFlip(),\n",
    "    RandomRotate90()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3b4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_img_paths = sorted(glob.glob(\"dataset/train/images/*.png\"))\n",
    "train_mask_paths = sorted(glob.glob(\"dataset/train/masks/*.png\"))\n",
    "val_img_paths = sorted(glob.glob(\"dataset/val/images/*.png\"))\n",
    "val_mask_paths = sorted(glob.glob(\"dataset/val/masks/*.png\"))\n",
    "\n",
    "train_dataset = UrbanDataset(train_img_paths, train_mask_paths, transform=transform)\n",
    "val_dataset = UrbanDataset(val_img_paths, val_mask_paths)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "460d87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # Backbone preentrenada\n",
    "    encoder_weights=\"imagenet\",     # Usa pesos de ImageNet\n",
    "    in_channels=3,                  # RGB\n",
    "    classes=1                       # 1 clase: manzana\n",
    ")\n",
    "\n",
    "loss_fn = smp.losses.DiceLoss(mode='binary')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "087674af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes encontradas: 4\n",
      "Máscaras encontradas: 4\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "train_img_paths = sorted(glob.glob(\"/workspaces/PI-EJM/dataset/train/images/*.png\"))\n",
    "train_mask_paths = sorted(glob.glob(\"/workspaces/PI-EJM/dataset/train/mask/*.png\"))\n",
    "\n",
    "print(\"Imágenes encontradas:\", len(train_img_paths))\n",
    "print(\"Máscaras encontradas:\", len(train_mask_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52d2c6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de pares: 4\n"
     ]
    }
   ],
   "source": [
    "# Emparejamiento seguro\n",
    "paired_train = list(zip(train_img_paths, train_mask_paths))\n",
    "train_img_paths, train_mask_paths = zip(*paired_train)\n",
    "\n",
    "print(f\"Cantidad de pares: {len(paired_train)}\")  # Debe salir 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c568914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UrbanDataset(train_img_paths, train_mask_paths, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)  # Ajusta batch_size según tu GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69a79158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import Resize\n",
    "\n",
    "transform = Compose([\n",
    "    Resize(256, 256),   # Asegura que imagen y máscara tengan el mismo tamaño\n",
    "    HorizontalFlip(),\n",
    "    VerticalFlip(),\n",
    "    RandomRotate90()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7bb71ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UrbanDataset(train_img_paths, train_mask_paths, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b48b0909",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    HorizontalFlip(),\n",
    "    VerticalFlip(),\n",
    "    RandomRotate90()\n",
    "], is_check_shapes=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfce29ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1\n",
    ").to(device)\n",
    "\n",
    "loss_fn = smp.losses.DiceLoss(mode='binary')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29cb6516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/PI-EJM/dataset/train/images/img_01.png CORRUPTO\n",
      "/workspaces/PI-EJM/dataset/train/images/img_02.png CORRUPTO\n",
      "/workspaces/PI-EJM/dataset/train/images/img_03.png CORRUPTO\n",
      "/workspaces/PI-EJM/dataset/train/images/img_04.png CORRUPTO\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for p in train_img_paths:\n",
    "    try:\n",
    "        Image.open(p).verify()\n",
    "        print(f\"{p} OK\")\n",
    "    except:\n",
    "        print(f\"{p} CORRUPTO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cccc5f8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file '/workspaces/PI-EJM/dataset/train/images/img_02.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnidentifiedImageError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m model.eval()\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Tomar un batch de imágenes y máscaras\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     images, masks = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     images, masks = images.to(device), masks.to(device)\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# Obtener predicciones\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mUrbanDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     image = np.array(\u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimg_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     22\u001b[39m     mask = np.array(Image.open(\u001b[38;5;28mself\u001b[39m.mask_paths[idx]).convert(\u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     23\u001b[39m     mask = mask / \u001b[32m255.0\u001b[39m  \u001b[38;5;66;03m# Normaliza a 0-1\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/PIL/Image.py:3580\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3578\u001b[39m     warnings.warn(message)\n\u001b[32m   3579\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[32m-> \u001b[39m\u001b[32m3580\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[31mUnidentifiedImageError\u001b[39m: cannot identify image file '/workspaces/PI-EJM/dataset/train/images/img_02.png'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Poner el modelo en modo evaluación\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Tomar un batch de imágenes y máscaras\n",
    "    images, masks = next(iter(train_loader))\n",
    "    images, masks = images.to(device), masks.to(device)\n",
    "    \n",
    "    # Obtener predicciones\n",
    "    preds = (model(images) > 0.5).float()\n",
    "    \n",
    "    # Seleccionar la primera imagen del batch para mostrar\n",
    "    image = images[0].permute(1,2,0).cpu().numpy()  # De C,H,W a H,W,C\n",
    "    mask = masks[0][0].cpu().numpy()               # Primer canal de la máscara\n",
    "    pred = preds[0][0].cpu().numpy()               # Primer canal de la predicción\n",
    "    \n",
    "    # Visualización\n",
    "    plt.figure(figsize=(12,4))\n",
    "    \n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Imagen original\")\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(mask)\n",
    "    plt.title(\"Máscara real\")\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(pred)\n",
    "    plt.title(\"Predicción U-Net\")\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
